[{"content":"When designing software1, using plain strings is a code smell, so much so that it can be almost seen as an antipattern.\nThere, I said it \u0026mdash; you shouldn\u0026rsquo;t use one of the most basic data structures you can possibly imagine. Now let me explain exactly what I mean by this: I think that by the end of this post you will at least understand my point of view, and maybe even agree with me.\nFirst, let\u0026rsquo;s clarify what a string is: a string is a sequence of bytes along with an encoding. In most programming languages, the encoding is set by the language designers and is implicit in the program (for example, the C standard library assumes that strings are ASCII-encoded with a NUL byte ending, Rust uses UTF-8, Java uses UTF-16, and so on). Even though the source code or the in-memory representation doesn\u0026rsquo;t acknowledge it, the character encoding is a critical piece of information, and is fundamentally what separates a string from a binary blob.\nThe encoding alone however, doesn\u0026rsquo;t make strings that much more powerful. Even if restricted to their encoding-allowed characters, strings can have any content, and there lies their problem: strings are too arbitrary to be useful. They don\u0026rsquo;t have invariants. They don\u0026rsquo;t have context.\nConsider a simple User class in Java:\n1 2 3 4 5 6 7 8 9 10 11 public class User { private final String username; private final String nickname; public User(String username, String nickname) { this.username = username; this.nickname = nickname; } // --snip-- } (I know this could have been a record, but let\u0026rsquo;s suppose object identity is meaningful for User and hidden behind that --snip-- comment \u0026#x1f609;). By looking at this class, I get exactly zero information about what User and its fields should represent (even more so in Java where both fields could be null). I can\u0026rsquo;t form any meaningful model about the program\u0026rsquo;s behaviour. Can the username be the same as the nickname? Can they be 10, 100, 1000 characters long? Is there any disallowed character? Can they be empty? Can they contain emojis? All of these are very concrete questions that cannot be answered unless I look at all instances where these two fields are validated, used and modified, hoping that all these instances are consistent with each other.\nLet me now modify the example very slightly:\n1 2 3 4 5 6 7 8 9 10 11 public class User { private final Username username; private final Nickname nickname; public User(Username username, Nickname nickname) { this.username = username; this.nickname = nickname; } // --snip-- } Just by using different types I can infer the following:\nusernames and nicknames are separate domain concepts, which cannot be intermixed (this constraint is materialized by having different types) usernames and nicknames are not directly comparable Username and Nickname may have different constraints, and if they have any they are most probably declared inside their respective classes I have a lot more information, even without looking at the implementation. Extensions of this pattern belong to the category of type-driven development, where powerful type systems can be used to encode even more properties about data into types. However, this line of reasoning is not limited to static type systems: any sufficiently type-safe2 language will do, even Python would do the job just fine.3\nReturning to our example, if I implement Nickname as follows:\n1 2 3 4 5 6 7 8 9 public record Nickname(String rawNickname) { public Nickname { Objects.requireNonNull(rawNickname); if (nickname.length() \u0026gt; 10) { throw new IllegalArgumentException(\u0026#34;Nicknames cannot have more than 10 characters\u0026#34;); } } } You instantly gain confidence in the fact that\nnicknames cannot be longer than 10 characters in the language encoding nicknames can be empty nicknames cannot be null (at least, what\u0026rsquo;s inside them) there are no explicit limitations to the allowed characters invalid Nickname instances cannot be constructed Properties 1-4 are characteristics that make a nickname a nickname in our example system. The fact that this kind of validation is all in one place rather than scattered across a codebase is nice, but nothing to shout about. The fifth property, however, is a game changer. Unconstructibility of invalid instances means that not only propreties 1-4 are valid here, it means that they are valid everywhere. I don\u0026rsquo;t have to check the whole codebase, I know for a fact that if any part of the program has access to a Nickname instance then it will have these 4 properties upheld. In more OOP-esque terms, these properties are effectively class invariants that are guaranteed upon construction. (I think that stating the idea in these terms hides a fair bit of its power).\nValidating plain strings at endpoints not only is error prone, it actively hides information about what the data is about. From an even more practical point of view, IDE autocomplete is also 10 times more useful (and precise) with more type information, so at the very least you get that.\nPlain strings would make sense only when you have human-readable text without any domain constraint and can be mixed with any other unconstrained text. Now tell me, when was the last time you had something like that? \u0026#x1f603;\nFeatured photo by Amie Bell.\nso no prototypes, no no-code tools, but programs that have to stand the test of time (or at least make economic sense)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis of course excludes Javascript.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPython however, having a dynamic type system, would require much more care\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-02-02T00:00:00Z","image":"http://giovanniberti.github.io/post/plain-string-smell/yarn_hu_92e57f147549288f.jpg","permalink":"http://giovanniberti.github.io/post/plain-string-smell/","title":"Plain strings are a code smell"},{"content":"A new obsession Picture this: middle of July, a warm sunny day relaxing on the beach with a few friends. Adele, a friend of mine, takes out a Sudoku magazine from her purse. It catches my eye, and I immediately ask her:\n\u0026ldquo;Hey Adi1, does it have Kropkis?\u0026rdquo;\n\u0026ldquo;Of course it does!\u0026rdquo; she smirks at me.\nKropkis are a recent drug for us. They are a variant of Sudoku with the addition that between each pair of neighboring cells there may be a dot, either white or black2.\nIf the dot is black, it means that the values in the cells must be one the double of the other, while if it is white it means that the values must be consecutive (in either order). If no dot is present, it means the values are neither doubles nor consecutives.\nAfter solving the only two Kropkis in the entire magazine, she tells me: \u0026ldquo;It\u0026rsquo;s a pity there aren\u0026rsquo;t any other Kropkis in here.\u0026rdquo;\nTo which I replied: \u0026ldquo;You know, I could write a program that generates them\u0026hellip;\u0026rdquo; \u0026#x1f609;\nTackling the problem We don\u0026rsquo;t have a direct way of building Kropkis (by \u0026ldquo;direct way\u0026rdquo; I mean a formula or a specific algorithm). One way to get around this is to search for a Kropki solution and then to minimize the number of hints to have a playable Kropki.\nNote that minimizing the number of hints has to account for uniqueness: we don\u0026rsquo;t want a Kropki that has multiple solutions! \u0026#x1f642;\nWhat about Sudokus? Here I\u0026rsquo;m talking about Kropkis, but the strategy outlined above works just as well for Sudokus!\nThe only difference between Sudoku generation and Kropki generation is how we check for uniqueness: hints are sufficient for Sudokus, while in Kropkis we have to add the dot constraints from the original solution.\nSearching for a solution From a mathematical point of view, the problem of generating a Kropki solution can be thought of a kind of Constraint Satisfaction Problem (CSP). In a CSP you have a set of variables, $x_1, \\dots, x_n$, each with a domain of possible values $D_1, \\dots, D_n$, and you want to find a value for each variable that is inside the respective domain and satisfies some constraints $f_1(x_1), \\dots, f_n(x_n)$. We can collectively call the collection of variables, domains and constraints $(\\mathbf{x}, \\mathbf{D}, \\mathbf{f})$ a model for a particular problem (I know this is very abstract, we\u0026rsquo;re going back to Kropkis very soon).\nGenerally speaking, for a given problem you can produce many different models (it largely depends on the meaning you assign to variables). For Kropkis, we can encode the problem of finding a solution with the following model:\n$$ \\begin{align*} S \u0026= {0, 1, \\dots, 8} \\\\ \\\\ V \u0026= {1, 2, \\dots, 9} \\\\ \\\\ x_{ij} \u0026\\in V \\quad \\forall i, j \\in S \\\\ \\\\ x_{ij} \u0026\\neq x_{ik} \\quad \u0026\\forall i, j, k \\in S, \\;j \\neq k \\tag{1} \\\\ \\\\ x_{ji} \u0026\\neq x_{ki} \\quad \u0026\\forall i, j, k \\in S, \\;j \\neq k \\tag{2} \\\\ \\\\ x_{st} \u0026\\neq x_{uv} \\quad \u0026\\forall s = 3k + i, \\tag{3} \\\\ \u0026\u0026 u = 3k + j, \\\\ \u0026\u0026 t = 3l + m, \\\\ \u0026\u0026 v = 3l + n, \\\\ \u0026\u0026 (i, m) \\neq (j, n), \\\\ \u0026\u0026 i, j, k, l, m, n \\in \\{0, 1, 2\\} \\\\ \\end{align*} $$ I know, it looks like gibberish. But this compact and elegant gibberish contains all the information we need to define what a Kropki is.\nTranslated back into English, the model says the following:\nWe have a set $S$ of coordinates (starting from zero because I\u0026rsquo;m a software engineer) We have a set $V$ of possible values (1 to 9) We have a variable $x$ that contains our solution Constraint $(1)$ says that for each row $i$ all values must be different (note that $x_{ij}$ stands for \u0026ldquo;the value at coordinate with row $i$ and column $j$\u0026rdquo;) Constraint $(2)$ says that for each column $i$ all values must be different Constraint $(3)$ says that for each block all values must be different. The trick is correctly encoding what a block is with indices, and you can convince yourself that the above equations work with the following diagram, where a single block is effectively identified by a pair of indices $(k, l)$: \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e This is how mathematically a Kropki solution is defined. It\u0026rsquo;s the same as the set of rules you can find in any magazine, just not in English \u0026#x1f643;. Note that the model did not mention anything about the dots, because every Sudoku solution is a Kropki solution. The dots are just \u0026ldquo;cosmetic\u0026rdquo; and do not alter the solution landscape in any significant way.\nDots and solutions Note that the fact that dots do not alter the model is true only because we are interested in any Kropki solution.\nIf we were looking for a solution to a specific Kropki, we would need to encode the various value constraints (e.g. \u0026ldquo;cell at $(1, 2)$ has value 8) as well as dot constraints (e.g. \u0026ldquo;there is a black dot between cells at $(2, 3)$ and $(2, 4)$\u0026rdquo;), and we would have a different model.\nOnce we do have a model, we can just write a program for a CSP solver and ask for a solution. Easy peasy!\nI chose to write the program in Python and leveraged the awesome CPMpy library to solve the model. All in all the model itself is fairly short:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import cpmpy as cp from itertools import product, chain grid = cp.intvar(1, 9, shape=(9, 9)) # our `x` # (1) all_different_in_row = (cp.AllDifferent(*(grid[r, i] for i in range(0, 9))) for r in range(0, 9)) # (2) all_different_in_col = (cp.AllDifferent(*(grid[i, c] for i in range(0, 9))) for c in range(0, 9)) # (3) block_intervals = [list(range(0, 3)), list(range(3, 6)), list(range(6, 9))] all_different_in_block = (cp.AllDifferent(grid[r, c] for r, c in product(*block)) for block in product(block_intervals, block_intervals)) model = cp.Model() for c in chain(all_different_in_row, all_different_in_col, all_different_in_block): model += c # Here\u0026#39;s a solution model.solve() print(f\u0026#34;Solution: {grid.value()=}\u0026#34;) Probably not the kind of code I would write for anything serious like a banking platform or a healthcare device, but for our purposes it does the job just fine.\nMinimizing a solution With the above piece of code we can easily get a solved Kropki. But we don\u0026rsquo;t want a solved Kropki. We want a solvable Kropki.\nGetting something we can play with means removing as much hints as possible (and drawing all the dots required by Kropki rules).\nAt the same time, we have to be careful when choosing what hint to remove: we can\u0026rsquo;t remove any hint if it means that the resulting Kropki has multiple solutions. Also, nothing says that we can\u0026rsquo;t start the other way around: from a blank grid we add hints from the solution we computed before until we have a Kropki with a unique solution. I\u0026rsquo;ll call these the subtractive and additive approaches respectively.\nWhathever the approach we choose, we still don\u0026rsquo;t have any concrete idea on how to find a playable solution. If we take the subtractive approach as an example, we could imagine that we start with a full Kropki grid and can select 81 possible hints for removal. For any first hint we remove, we can then check if the solution is minimal3 (i.e. no other hints can be removed such that the solution is unique) and select another hint if it\u0026rsquo;s not.\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e Here you can see a representation of this concept. Starting from a start node we can \u0026ldquo;make a move\u0026rdquo; and remove one hint (by following the arrows), and then remove another one, and so on (for example a possible path is through $(0, 0)$ and $(0, 1)$, meaning that we first remove the hint at $(0, 0)$ and remove the hint at $(0,1)$). Note that in the above diagram the order of hint removals is important: the path $(0, 0) \\rightarrow (0, 1)$ is different from the path $(0, 1) \\rightarrow (0, 0)$. But that\u0026rsquo;s not needed in our case, because the resulting board would be the same! That means that instead of considering each node as a \u0026ldquo;move\u0026rdquo; (and implicitly the path that was taken to get to the node as a \u0026ldquo;history\u0026rdquo;), we can map each node to a set of moves: the set of moves that a path with those moves would generate, regardless of the order.\nThe resuling diagram would be like this, where each node represents the set of moves:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e Note that now there are two arrows going into the node $\\lbrace (0,0), (0,1) \\rbrace$. This change may seem inconsequential, but discarding the relevancy of order means reducing drastically the size of this diagram (thus the number of nodes our program will have to check).\nWe can even compute how many nodes we saved! Before, after $n$ nodes selected we could make $(81 - n)$ possible choices for each node. Expanding that idea and calling $s_n$ the total number of possible choices after $n$ moves:\n$$ \\begin{align*} \u0026s_0 = 81 \\\\ \u0026s_1 = s_0 (81 - 1) \\\\ \u0026s_2 = s_1 (81 - 2) \\\\ \u0026\\vdots \\\\ \u0026s_j = s_{j - 1} (81 - j) = \\prod_{k = 0}^{j} (81 - k) = \\frac{81!}{(81 - j - 1)!} = (81)_{j + 1}\\\\ \\\\ N \u0026= \\sum_{i = 0}^{81} s_i \\\\ \u0026= \\sum_{i = 0}^{81} \\frac{81!}{(81 - j - 1)!} \\\\ \u0026\\approx 1.5 \\cdot 10^{121} \\end{align*} $$ Where $(n)_k$ is the number of $k$-permutations of a set of $n$ elements. Note that at each $s_j$ we have $j + 1$ hints selected.\nAfter discarding the order we get the same computation, except that $s_j$ must be divided by the number of paths that can generate the same set of moves. This is the same as the number of different permutations (i.e. orderings) of a set of $j + 1$ elements, i.e. $(j + 1)!$.\n$$ \\begin{align*} \u0026s_0 = 81 \\\\ \u0026s_1 = \\frac{s_0 (81 - 1)}{2!} \\\\ \u0026s_2 = \\frac{s_1 (81 - 2)}{3!} \\\\ \u0026\\vdots \\\\ \u0026s_j = \\frac{s_{j - 1} (81 - j)}{(j+1)!} = \\frac{(81)_{j + 1}}{(j + 1)!} = \\bold{C}(81, j + 1) = \\binom{81}{j + 1} \\\\ \\\\ N \u0026= \\sum_{i = 0}^{81} s_i \\\\ \u0026= \\sum_{i = 0}^{81} \\binom{81}{j + 1} \\\\ \u0026\\approx 2.4 \\cdot 10^{24} \\end{align*} $$ That\u0026rsquo;s a 97 order of magnitudes reduction! Still too big to naively iterate through all $10^{24}$ nodes until we find a minimal solution. We can instead exploit the structure of our problem, and the diagram we made before is all we need. That diagram is, in fancy mathy words, a graph where each node encodes a set of removed hints, and each edge (i.e. arrow) indicates a \u0026ldquo;one-move\u0026rdquo; distance between nodes.\nThe kind of problem we are describing is a (local) search. I won\u0026rsquo;t describe here all the nitty-gritty details of search algorithms, because there are plenty of resources online that can do a far better job than me, and for Kropkis there is no big insight in understanding exactly how they work. If you are curious, I used the A* search algorithm in the hopes of finding a good heuristic, but I couldn\u0026rsquo;t find one, so I stuck with $h(x) = 0$.\nSqueezing performance By combining a CSP with a search algorithm we already have a Kropki generator. Our job is done! But I don\u0026rsquo;t want to wait several minutes to have a Kropki. I\u0026rsquo;d much rather wait at most a few seconds.\nI was stuck on how to optimize search for quite a bit. I even considered rewriting the program from Python to another language like Rust (profiling showed that a lot of the time was spent in the CSP solver in type checking integers at runtime when checking for minimality). I rewrote the program from the additive approach (it seemed more natural given that we are trying to minimize the number of hints, so starting from 0 instead of 81 seemed a good start) to the subtractive approach in order to get a different perspective on the problem.\nAt one point I just threw my hands up and said: \u0026ldquo;Whatever, I don\u0026rsquo;t care about the minimal solution, it just has to be good enough\u0026rdquo;. An approximate solution would be far better if it would be capable of unlocking a big speedup. And the switch to the subtractive approach made computing approximate solutions extremely natural. For the subtractive approach, you just have to start from a subset of the initial hints instead of the full board (i.e. a partial solution). Starting from 10 hints only is in fact extremely faster than starting from 81 hints: it won\u0026rsquo;t guarantee that the solution you find is optimal, but it surely is minimal (i.e. you may find a solution with 6 hints while if you started with 81 the optimal solution would have had 5, but you cannot remove any of the 6 hints you found and still have a unique solution).\nThis approach worked very well, and is again related to the structure of the problem: Kropkis in fact need very little hints to ensure uniqueness of a solution, so by randomly removing many of the initial hints it\u0026rsquo;s very likely that you didn\u0026rsquo;t discard good solutions4.\nBut I wasn\u0026rsquo;t satisfied still with the overall perfomance. I felt like I was leaving something on the table performance-wise. And I was. You see, ignoring history reduced a lot our search space, but there is still some redundancy there: there are still multiple paths that get to the same result. If we managed to fix the exploration order, there would be no more duplication. For example, if we decide to evaluate nodes in the natural coordinate order ($(0, 0)$ to $(8, 8)$, row by row) it means that once we get to the second row, we will not be able to change the choices we made for the first row. And that\u0026rsquo;s good! If the choices we made for our first row are included in the optimal solution, there is no way we can\u0026rsquo;t get to the optimal solution (because in general the order of choices is not relevant to the solution).\nLet\u0026rsquo;s compute the impact of fixing the exploration order. For step $s_0$ there is obviously no change, while for the second step fixing the order means that we are allowed to choose cells that come only after the cell chosen at step 0. For step three the same logic applies: we can\u0026rsquo;t choose cells that come before the maximum cell that we have already chosen, and because the cell choices can only grow in one direction, it means that the maximum cell is the one chosen at the previous step.\nFocusing on the other steps, for each candidate cell $i$ we have $(81 - i)$ neighboring nodes (if we choose the first cell we can then choose any other at the next step, while if we choose the last it means we consider the whole grid as the candidate minimal solution). Writing down and computing that:\n$$ \\begin{align*} s_0 \u0026= 81 \\\\ s_1 \u0026= \\sum_{i = 1}^{81} (81 - i) \\\\ s_2 \u0026= \\sum_{i = 2}^{81} (81 - i) \\\\ \\vdots\u0026 \\\\ s_j \u0026= \\sum_{i = j}^{81} (81 - i) \u0026\\text{(substitute $k = 81 - i - j$)} \\\\ \u0026= \\sum_{k = 0}^{81 - j} (81 - j - k) \u0026\\text{(substitute $l = 81 - j - k$)} \\\\ \u0026= \\sum_{l = 0}^{81 - j} l = \\binom{81 - j}{2} \\\\ \\\\ N \u0026= \\sum_{i = 0}^{81} s_i \\\\ \u0026= 81 + \\sum_{i = 1}^{81} \\binom{81 - j}{2} \\\\ \u0026= 85\\,401 \\end{align*} $$ A 118 orders of magnitude reduction from the initial search space! Visually, fixing the exploration order can be seen as follows:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?\u003e In this case we are considering a \u0026ldquo;path\u0026rdquo; (in the previous sense) from $(0, 0)$ to $(0, 4)$ (and assigning to them 2 and 4 respectively) and simultaneously excluding cells from $(0, 1)$ to $(0, 3)$ by forcing them to be empty. In every path stemming from this we will never assign values to the cells before $(0,4)$.\nFixing the order is not difficult per se, but combining it with partial solutions seemed tricky: given a partial solution $S$ I would have to write a function that computed an ordering of cell grids that had all the cells in $S$ as a prefix, and then computed an ordering for the remaining cells that would depend on $S$ only.\nAfter banging my head on this for a while, I wrote this plain snippet that did the job:\n1 2 3 4 5 6 7 8 def prefixed_sequence_generator(prefix: list[tuple[int, int]]): def sequence(): grid = grid_coords() - set(prefix) yield from prefix yield from grid return sequence Basically we get a list ($S$) in input and return a generator that yields the elements in $S$ first and then relies on Python\u0026rsquo;s set ordering for all other elements.\nWith both these tricks implemented (partial solutions and order fixing), I can get a Kropki generated in under 2 seconds on my laptop.\nTying everything together Now that we have our algorithm, we just need a backend to expose Kropki generation and a frontend to visualize Kropkis \u0026#x1f525;.\nI wrote the server using FastAPI and the frontend with React, nothing special there. What I think it\u0026rsquo;s worth mentioning is how I decided to encode Kropkis (both solved and playable). I named this encoding Kropki Easy Notation (KEN for short), a bit like FEN in chess. It\u0026rsquo;s very simple: each row is delimited by /, and each cell has two possible encodings:\nN if the cell has a value and no dots where N is the value inside (Nbr) if the cell has dots, where N is the value inside (omitted if not present), b is the encoding of the bottom dot and r is the encoding of the right dot Dots are always encoded, with w if the dot is white, k if the dot is black and x if the dot is not present. Missing values are encoded using letters, from A corresponding to one empty cell, B corresponding to two consecutive empty cells, and so on until H (eight consecutive empty cells).\nA generated Kropki might be like this:\n(wx)A(wx)(xw)(kx)D/B(xw)D(kw)A/(xw)(wk)A(ww)A(ww)C/(wx)(wx)(ww)A(xk)A(wx)(wx)A/(kx)B(kx)B(xw)A(wx)/(xw)A(xk)A(wx)(kx)(xw)(kx)A/B(wx)(xw)A(xw)A(xw)(kx)/(xw)(xk)C(kk)A(wk)A/B(xw)(xw)C(xw) And has this solution:\n618327495/579814623/342569817/937648251/826175349/451293768/194786532/763952184/285431976 Viewable here. Or you can see the result here below:\nGiven that I found KEN, it followed naturally that the frontend would be named BARBIE (Board A-star Based Interactive Explorer). I still haven\u0026rsquo;t decided on what easter egg to include for \u0026#x1f575;\u0026#xfe0f;\u0026#x269b;\u0026#xfe0f; though.\nAnd here it is! It\u0026rsquo;s deployed on Fly.io for the backend (free tier) and Netlify for the frontend (also free tier), so it might be a bit slow to generate kropkis the first time you do it (and currently the frontend does not have input fields to write numbers down). Happy Kropking! \u0026#x1f389;\nP.S.: If you want to check out the source code, you can get the generator here and the frontend here \u0026#x1f642;\nFeatured photo by Camille Minoufflet.\nFriendly Italian nickname for \u0026ldquo;Adele\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKropki means \u0026ldquo;dots\u0026rdquo; in Polish\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTo check for minimality we use the same model used for generation and add all dot constraints from the full solution, all remaining value constraints and remove one value constraint at a time. For each iteration we can ask the solver for two solutions and keep going if it can find more than one. If we don\u0026rsquo;t finish the loop early it means that it\u0026rsquo;s impossible to remove a value constraint while keeping uniqueness, meaning that the solution we found is minimal.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis property is usually referred in other contexts as sparsity, with the twist that sparse solutions have many zeros instead of \u0026ldquo;many holes\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-12-08T00:00:00Z","image":"http://giovanniberti.github.io/post/generating-kropkis/beach_hu_c04656dd670c3ca4.jpg","permalink":"http://giovanniberti.github.io/post/generating-kropkis/","title":"Generating Kropkis"}]